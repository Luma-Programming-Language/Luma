@module "lexer"

@use "common" as com

pub const number_to_kind -> fn (val: int) *byte {
  switch (val) {
    com::TokenKind::Number -> return "Number";
    com::TokenKind::LParen -> return "LParen";
    com::TokenKind::RParen -> return "RParen";
    com::TokenKind::At     -> return "At";
    com::TokenKind::Semi   -> return "Semi";
    com::TokenKind::Plus   -> return "Plus";
    com::TokenKind::Minus  -> return "Minus";
    com::TokenKind::Star   -> return "Star";
    com::TokenKind::Slash  -> return "Slash";
    com::TokenKind::Carrot -> return "Carrot";
    com::TokenKind::Mod    -> return "Mod";
    com::TokenKind::EOF    -> return "EOF";
  }
}

pub const create_lexer -> fn (path: *byte) Lexer {
  return Lexer { line: 1, col: 0, src: path, current: path };
}

#returns_ownership
pub const token_value_string -> fn (tok: *Token) *byte {
  let s: *byte = cast<*byte>(alloc((tok.len + 1) * sizeof<byte>));
  loop [i: int = 0](i < tok.len) : (++i) {
    s[i] = tok.val[i];
  }  
  s[tok.len] = '\0';
  return s;
}

const SINGLE_SYMBOL_COUNT: int = 10;
const SingleSymbol -> struct { val: byte, kind: int }; 
const  single_symbol_map: [SingleSymbol; 10] = [
  SingleSymbol { val: '(', kind: com::TokenKind::LParen }, 
  SingleSymbol { val: ')', kind: com::TokenKind::RParen },
  SingleSymbol { val: ';', kind: com::TokenKind::Semi   },
  SingleSymbol { val: '@', kind: com::TokenKind::At     },
  SingleSymbol { val: '+', kind: com::TokenKind::Plus   }, 
  SingleSymbol { val: '-', kind: com::TokenKind::Minus  },
  SingleSymbol { val: '*', kind: com::TokenKind::Star   }, 
  SingleSymbol { val: '/', kind: com::TokenKind::Slash  },
  SingleSymbol { val: '^', kind: com::TokenKind::Carrot },
  SingleSymbol { val: '%', kind: com::TokenKind::Mod    },
];

const lookup_single -> fn (val: byte) int {
  loop [i: int = 0](i < SINGLE_SYMBOL_COUNT) : (++i) {
    if (single_symbol_map[i].val == val) 
      return single_symbol_map[i].kind;
  }
  return -1;
}

const peek -> fn (lx: *Lexer, offset: int) byte { 
  return lx.current[offset]; 
}

const advance -> fn (lx: *Lexer) byte {
  let c: byte = peek(lx, 0);
  lx.current = cast<*byte>(cast<int>(lx.current) + 1);

  if (c == '\n') {
    lx.line = lx.line + 1;
    lx.col = 0;
  } elif (c != '\0') {
    lx.col = lx.col + 1;
  }
  
  return c;
}

const is_end -> fn (lx: *Lexer) int { 
  if (peek(lx, 0) == '\0') return 1;
  return 0;
}

const is_digit -> fn (c: byte) bool {
  return (c >= '0' && c <= '9');
}

const is_whitespace -> fn (c: byte) bool {
  return (c == ' ' || c == '\t' || c == '\n' || c == '\r');
}

const skip_whitespace -> fn (lx: *Lexer) void {
  loop (is_end(lx) == 0 && 
        is_whitespace(peek(lx, 0))) {
    advance(lx);
  }
}

const make_token -> fn (val: *byte, kind: int, len: int) Token {
  return Token { val: val, kind: kind, len: len };
}

pub const next_token -> fn (lx: *Lexer) Token {
  skip_whitespace(lx);

  if (is_end(lx) == 1)
    return make_token(lx.current, com::TokenKind::EOF, 0);
  
  let start: *byte = lx.current;
  let c: byte = peek(lx, 0);
  
  // Check for numbers
  if (is_digit(c)) {
    let len: int = 0;
    loop (is_end(lx) == 0 && is_digit(peek(lx, 0))) {
      advance(lx);
      len = len + 1;
    }
    return make_token(start, com::TokenKind::Number, len);
  }
  
  // Check for single-character tokens
  let kind: int = lookup_single(c);
  if (kind != -1) {
    advance(lx);
    return make_token(start, kind, 1);
  }
  
  // Unknown character - skip it and try again
  advance(lx);
  return next_token(lx);
}
